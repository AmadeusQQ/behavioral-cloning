{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import fnmatch\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Activation, Dense, Flatten\n",
    "from keras.models import load_model, Sequential\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAMERA_COUNT = 3\n",
    "\n",
    "DRIVING_LOG_PATH = './data'\n",
    "DRIVING_LOG_FILE = 'driving_log.csv'\n",
    "\n",
    "CENTER_IMAGE_REGULAR_EXPRESSION = 'center*'\n",
    "IMAGE_PATH = './data/IMG'\n",
    "\n",
    "SET_SIZE = 256\n",
    "EPOCH = 4\n",
    "VALIDATION_SET_SIZE = 0.2\n",
    "\n",
    "center_file = 'center_2016_12_01_13_37_16_570.jpg'\n",
    "left_file = 'left_2016_12_01_13_37_16_570.jpg'\n",
    "right_file = 'right_2016_12_01_13_37_16_570.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "Use data by Udacity.\n",
    "\n",
    "Source: https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\n",
    "\n",
    "Size: 322.8 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not execute this cell as it will read all images into memory\n",
    "# data = np.array([cv2.imread(os.path.join(IMAGE_PATH, file)) for file in os.listdir(IMAGE_PATH)], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "print(reader.__next__())\n",
    "print(reader.__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = len(os.listdir(IMAGE_PATH))\n",
    "\n",
    "print('Count:', count)\n",
    "print('Frames:', count / CAMERA_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.array([1 for file in os.listdir(IMAGE_PATH) if fnmatch.fnmatch(file, CENTER_IMAGE_REGULAR_EXPRESSION)], dtype = 'float32')\n",
    "print('Center image count:', data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center = cv2.imread(os.path.join(IMAGE_PATH, center_file))\n",
    "print('Shape:', image_center.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_left = cv2.imread(os.path.join(IMAGE_PATH, left_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_left, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_right = cv2.imread(os.path.join(IMAGE_PATH, right_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_right, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_resized = cv2.resize(image_center, (32, 16))\n",
    "print('Shape:', image_center_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center_resized, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_start = 60\n",
    "y_end = image_center.shape[0] - 20\n",
    "x_start = 0\n",
    "x_end = image_center.shape[1]\n",
    "\n",
    "image_center_cropped = image_center[y_start:y_end, x_start:x_end]\n",
    "print('Shape:', image_center_cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center_cropped, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_grayscale = cv2.cvtColor(image_center, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(image_center_grayscale, cmap = 'gray')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_cropped_grayscale = cv2.cvtColor(image_center_cropped, cv2.COLOR_BGR2GRAY)\n",
    "image_center_cropped_grayscale_resized = cv2.resize(image_center_cropped_grayscale, (32, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(image_center_cropped_grayscale_resized, cmap = 'gray')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "reader.__next__()\n",
    "\n",
    "features = np.array(\n",
    "    [\n",
    "        cv2.imread(\n",
    "            os.path.join(\n",
    "                IMAGE_PATH,\n",
    "                reader\n",
    "                    .__next__()[0]\n",
    "                    .strip('IMG/')\n",
    "            )\n",
    "        )\n",
    "        for index in range(SET_SIZE)\n",
    "    ],\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "reader.__next__()\n",
    "\n",
    "labels = np.array(\n",
    "    [\n",
    "        reader.__next__()[3]\n",
    "        for index in range(SET_SIZE)\n",
    "    ],\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = shuffle(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    lower_bound = -0.5\n",
    "    upper_bound = 0.5\n",
    "    minimum_pixel = 0\n",
    "    maximum_pixel = 255\n",
    "    \n",
    "    return lower_bound + (\n",
    "        (image_data - minimum_pixel) *\n",
    "        (upper_bound - lower_bound) /\n",
    "        (maximum_pixel - minimum_pixel)\n",
    "    )\n",
    "\n",
    "normalized_features = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "\n",
    "assert math.isclose(\n",
    "    np.min(normalized_features),\n",
    "    -0.5,\n",
    "    abs_tol = epsilon\n",
    ") and math.isclose(\n",
    "    np.max(normalized_features),\n",
    "    0.5,\n",
    "    abs_tol = epsilon\n",
    "), 'Range is: {} to {}. It must be -0.5 to 0.5'.format(\n",
    "    np.min(normalized_features),\n",
    "    np.max(normalized_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (256, 160, 320, 3)\n",
      "Labels shape: (256,)\n"
     ]
    }
   ],
   "source": [
    "print('Features shape:', normalized_features.shape)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design model\n",
    "\n",
    "Use model by NVIDIA.\n",
    "\n",
    "Source: https://arxiv.org/pdf/1604.07316v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width = normalized_features.shape[1]\n",
    "length = normalized_features.shape[2]\n",
    "depth = normalized_features.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comment out dimensions from NVIDIA model after testing model output shape\n",
    "# width = 66\n",
    "# length = 200\n",
    "# depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "convolution_filter = 24\n",
    "kernel_size = 5\n",
    "stride_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 36\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 48\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 64\n",
    "kernel_size = 3\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print('Shape:', model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "history = model.fit(normalized_features, labels, nb_epoch = EPOCH, validation_split = VALIDATION_SET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "1.  Final validation loss = 0.0352\n",
    "    - Final training loss = 0.0083\n",
    "    - Model may be overfitting as difference between training and validation loss increases per epoch\n",
    "    - Loss becomes not a number when training model again\n",
    "    - Image\n",
    "        - Center\n",
    "        - Normalized\n",
    "    - Set size\n",
    "        - Training = 204\n",
    "        - Validation = 52\n",
    "    - Model\n",
    "        - Stochastic gradient descent\n",
    "        - Epoch = 4\n",
    "        - Longest epoch = 18 s\n",
    "        - Samples per second = 204 / 18 = 11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
