{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import fnmatch\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.models import model_from_json, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAMERA_COUNT = 3\n",
    "\n",
    "DRIVING_LOG_PATH = './data'\n",
    "DRIVING_LOG_FILE = 'driving_log.csv'\n",
    "\n",
    "CENTER_IMAGE_REGULAR_EXPRESSION = 'center*'\n",
    "IMAGE_PATH = './data/IMG'\n",
    "\n",
    "SET_SIZE = 512\n",
    "EPOCH = 4\n",
    "VALIDATION_SET_SIZE = 0.2\n",
    "\n",
    "center_camera_file = 'center_2016_12_01_13_37_16_570.jpg'\n",
    "left_camera_file = 'left_2016_12_01_13_37_16_570.jpg'\n",
    "right_camera_file = 'right_2016_12_01_13_37_16_570.jpg'\n",
    "\n",
    "hard_left_file = 'center_2016_12_01_13_39_28_024.jpg'\n",
    "hard_right_file = 'center_2016_12_01_13_38_46_752.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "Use data by Udacity.\n",
    "\n",
    "Source: https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\n",
    "\n",
    "Size: 322.8 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use beta simulator to gather data using mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get at least 40,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use generator to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit steering angle for left and right camera images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get features and labels that correspond to hard left turn, straight, and hard right turn\n",
    "# Tune model to predict these 3 steering angles correctly\n",
    "# left = np.array(cv2.imread(\n",
    "#     os.path.join(\n",
    "#         IMAGE_PATH,\n",
    "#         hard_left_file\n",
    "#     )\n",
    "# ), dtype = 'float32')\n",
    "# center = np.array(cv2.imread(\n",
    "#     os.path.join(\n",
    "#         IMAGE_PATH,\n",
    "#         center_camera_file\n",
    "#     )\n",
    "# ), dtype = 'float32')\n",
    "# right = np.array(cv2.imread(\n",
    "#     os.path.join(\n",
    "#         IMAGE_PATH,\n",
    "#         hard_right_file\n",
    "#     )\n",
    "# ), dtype = 'float32')\n",
    "# features = np.stack((left, center, right))\n",
    "\n",
    "# labels = np.array([-0.9426954, 0, 1], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "reader.__next__()\n",
    "\n",
    "features = np.array(\n",
    "    [\n",
    "        cv2.imread(\n",
    "            os.path.join(\n",
    "                IMAGE_PATH,\n",
    "                reader\n",
    "                    .__next__()[0]\n",
    "                    .strip('IMG/')\n",
    "            )\n",
    "        )\n",
    "        for index in range(SET_SIZE)\n",
    "    ],\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "reader.__next__()\n",
    "\n",
    "labels = np.array(\n",
    "    [\n",
    "        reader.__next__()[3]\n",
    "        for index in range(SET_SIZE)\n",
    "    ],\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample():\n",
    "    file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    reader.__next__()\n",
    "    \n",
    "    while True:\n",
    "        line = reader.__next__()\n",
    "        \n",
    "        yield np.array(\n",
    "            cv2.imread(\n",
    "                os.path.join(\n",
    "                    IMAGE_PATH,\n",
    "                    line[0].strip('IMG/')\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "generator = generate_sample()\n",
    "\n",
    "image = next(generator)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
      "['IMG/center_2016_12_01_13_30_48_287.jpg', ' IMG/left_2016_12_01_13_30_48_287.jpg', ' IMG/right_2016_12_01_13_30_48_287.jpg', ' 0', ' 0', ' 0', ' 22.14829']\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(DRIVING_LOG_PATH, DRIVING_LOG_FILE), 'r')\n",
    "reader = csv.reader(file)\n",
    "\n",
    "print(reader.__next__())\n",
    "print(reader.__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = len(os.listdir(IMAGE_PATH))\n",
    "\n",
    "print('Count:', count)\n",
    "print('Frames:', count / CAMERA_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.array([1 for file in os.listdir(IMAGE_PATH) if fnmatch.fnmatch(file, CENTER_IMAGE_REGULAR_EXPRESSION)], dtype = 'float32')\n",
    "print('Center image count:', data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center = cv2.imread(os.path.join(IMAGE_PATH, center_camera_file))\n",
    "print('Shape:', image_center.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_left = cv2.imread(os.path.join(IMAGE_PATH, left_camera_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_left, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_right = cv2.imread(os.path.join(IMAGE_PATH, right_camera_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_right, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_hard_left = cv2.imread(os.path.join(IMAGE_PATH, hard_left_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_hard_left, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_hard_right = cv2.imread(os.path.join(IMAGE_PATH, hard_right_file))\n",
    "pyplot.imshow(cv2.cvtColor(image_hard_right, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.describe(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.hist(labels)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_resized = cv2.resize(image_center, (32, 16))\n",
    "print('Shape:', image_center_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center_resized, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_start = 64\n",
    "y_end = image_center.shape[0] - 30\n",
    "x_start = 60\n",
    "x_end = image_center.shape[1] - 60\n",
    "\n",
    "image_center_cropped = image_center[y_start:y_end, x_start:x_end]\n",
    "print('Shape:', image_center_cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(cv2.cvtColor(image_center_cropped, cv2.COLOR_BGR2RGB))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_cropped_grayscale = cv2.cvtColor(image_center_cropped, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(image_center_cropped_grayscale, cmap = 'gray')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_center_cropped_grayscale_resized = cv2.resize(image_center_cropped_grayscale, (32, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(image_center_cropped_grayscale_resized, cmap = 'gray')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "features, labels = shuffle(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    lower_bound = -0.5\n",
    "    upper_bound = 0.5\n",
    "    minimum_pixel = 0\n",
    "    maximum_pixel = 255\n",
    "    \n",
    "    return lower_bound + (\n",
    "        (image_data - minimum_pixel) *\n",
    "        (upper_bound - lower_bound) /\n",
    "        (maximum_pixel - minimum_pixel)\n",
    "    )\n",
    "\n",
    "normalized_features = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "\n",
    "assert math.isclose(\n",
    "    np.min(normalized_features),\n",
    "    -0.5,\n",
    "    abs_tol = epsilon\n",
    ") and math.isclose(\n",
    "    np.max(normalized_features),\n",
    "    0.5,\n",
    "    abs_tol = epsilon\n",
    "), 'Range is: {} to {}. It must be -0.5 to 0.5'.format(\n",
    "    np.min(normalized_features),\n",
    "    np.max(normalized_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Features shape:', normalized_features.shape)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design model\n",
    "\n",
    "Use model by NVIDIA.\n",
    "\n",
    "Source: https://arxiv.org/pdf/1604.07316v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width = normalized_features.shape[1]\n",
    "length = normalized_features.shape[2]\n",
    "depth = normalized_features.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add normalization layer\n",
    "# Add dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convolution_filter = 24\n",
    "kernel_size = 5\n",
    "stride_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 36\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 48\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    subsample = (stride_size, stride_size),\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "\n",
    "convolution_filter = 64\n",
    "kernel_size = 3\n",
    "\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "model.add(Convolution2D(\n",
    "    convolution_filter,\n",
    "    kernel_size,\n",
    "    kernel_size,\n",
    "    border_mode = 'valid',\n",
    "    input_shape = (width, length, depth)\n",
    "))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "print('Shape:', model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training on a GPU is 20 times faster than CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use transfer learning to refine a working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = 'mse')\n",
    "history = model.fit(normalized_features, labels, nb_epoch = EPOCH, validation_split = VALIDATION_SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.predict(normalized_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open('model.json', 'w')\n",
    "json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "Rubric: https://review.udacity.com/#!/rubrics/432/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment|Image|Set size|Optimizer|Learning rate|Epoch|Training time|Samples per second|Loss|Notes\n",
    "-|\n",
    "1|Center, normalized|256|Stochastic gradient descent|0.01|4|67 s|15.3|0.0194|Model may be overfitting as difference between training and validation loss increases per epoch. Loss becomes not a number when training model again.\n",
    "2|Center, normalized|3|Stochastic gradient descent|0.000001|4|1 s|12|0.9166|Loss no longer becomes not a number due to reduced learning rate. Model predicts steering direction correctly.\n",
    "3|Center, normalized|256|Stochastic gradient descent|0.000001|4|66 s|15.5|0.0533|Loss plateaus. Validation loss is greater than training loss. Car makes a hard left turn.\n",
    "4|Center, normalized|512|Stochastic gradient descent|0.000001|4|134 s|15.3|0.0258|Loss plateaus. Training loss is greater than validation loss. Car makes a hard right turn.\n",
    "5|Center, normalized|512|Adaptive movement estimation|0.000001|4|142 s|14.4|0.0266|Validation loss is greater than training loss. Car makes a hard right turn with brief hard left turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.legend(['Training', 'Validation'])\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
